{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dalle-mini.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1WyBl1dlLXgsKHweWosAOTXDS2V2Dx8dq",
      "authorship_tag": "ABX9TyNF9gJcTFgYBWmDvYeF/T8G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralTextToImage/blob/main/dalle_mini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCskRiNym_LW"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">DALL-E MINI<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Neural text-to-image</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralImageGeneration\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Dalle-mini generates images from text input. \n",
        "\n",
        "### Tips\n",
        "- You may queue infinite text prompts by separating them by semicolon (`;`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6-8KXU6m8TM",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "pip_packages = 'dalle-mini'\n",
        "main_repository = ''\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <small>Use `mini-1` if you are on Colab free plan.</small>\n",
        "dalle_model = \"mega-1-fp16\" #@param [\"mega-1-fp16\", \"mini-1\"]\n",
        "\n",
        "\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive is True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if main_repository is not '':\n",
        "  !git clone {main_repository}\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#--Dalle mini--\n",
        "!pip install -q git+https://github.com/patil-suraj/vqgan-jax.git\n",
        "\n",
        "\n",
        "if dalle_model == 'mega-1-fp16':\n",
        "  DALLE_MODEL = \"dalle-mini/dalle-mini/mega-1-fp16:latest\"\n",
        "else:\n",
        "  DALLE_MODEL = \"dalle-mini/dalle-mini/mini-1:v0\"\n",
        "DALLE_COMMIT_ID = None\n",
        "VQGAN_REPO = \"dalle-mini/vqgan_imagenet_f16_16384\"\n",
        "VQGAN_COMMIT_ID = \"e93a26e7707683d349bf5d5c41c5b0ef69b677a9\"\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "jax.local_device_count()\n",
        "\n",
        "from dalle_mini import DalleBart, DalleBartProcessor\n",
        "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
        "from transformers import CLIPProcessor, FlaxCLIPModel\n",
        "\n",
        "model, params = DalleBart.from_pretrained(\n",
        "    DALLE_MODEL, revision=DALLE_COMMIT_ID, dtype=jnp.float16, _do_init=False\n",
        ")\n",
        "\n",
        "vqgan, vqgan_params = VQModel.from_pretrained(\n",
        "    VQGAN_REPO, revision=VQGAN_COMMIT_ID, _do_init=False\n",
        ")\n",
        "\n",
        "from flax.jax_utils import replicate\n",
        "\n",
        "params = replicate(params)\n",
        "vqgan_params = replicate(vqgan_params)\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "# model inference\n",
        "@partial(jax.pmap, axis_name=\"batch\", static_broadcasted_argnums=(3, 4, 5, 6))\n",
        "def p_generate(\n",
        "    tokenized_prompt, key, params, top_k, top_p, temperature, condition_scale\n",
        "):\n",
        "    return model.generate(\n",
        "        **tokenized_prompt,\n",
        "        prng_key=key,\n",
        "        params=params,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        temperature=temperature,\n",
        "        condition_scale=condition_scale,\n",
        "    )\n",
        "\n",
        "\n",
        "# decode image\n",
        "@partial(jax.pmap, axis_name=\"batch\")\n",
        "def p_decode(indices, params):\n",
        "    return vqgan.decode_code(indices, params=params)\n",
        "\n",
        "import random\n",
        "\n",
        "# create a random key\n",
        "seed = random.randint(0, 2**32 - 1)\n",
        "key = jax.random.PRNGKey(seed)\n",
        "\n",
        "from dalle_mini import DalleBartProcessor\n",
        "\n",
        "processor = DalleBartProcessor.from_pretrained(DALLE_MODEL, revision=DALLE_COMMIT_ID)\n",
        "#--//Dalle mini--\n",
        "\n",
        "\n",
        "\n",
        "#--ISR--\n",
        "%cd /content/\n",
        "!git clone https://github.com/saadz-khan/image-super-resolution\n",
        "%cd image-super-resolution\n",
        "!python setup.py install\n",
        "from ISR.models import RRDN\n",
        "rdn = RRDN(weights='gans')\n",
        "%cd /content/\n",
        "#--//ISR--\n",
        "\n",
        "\n",
        "\n",
        "output.clear()\n",
        "# !nvidia-smi\n",
        "op(c.ok, 'Setup finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2z1os4Bocdy",
        "cellView": "form"
      },
      "source": [
        "#@title # Do stuff\n",
        "generate_image_of = \"George Costanza ice fishing 2kg siika\" #@param {type:\"string\"}\n",
        "\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "superres = True #@param {type:\"boolean\"}\n",
        "number_of_images = 6 #@param {type:\"slider\", min:1, max:9}\n",
        "\n",
        "uniq_id = gen_id()\n",
        "\n",
        "\n",
        "# Output\n",
        "if not os.path.isdir(drive_root+output_dir):\n",
        "  os.mkdir(drive_root+output_dir)\n",
        "dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# -- DO THINGS --\n",
        "prompts = [x.strip() for x in generate_image_of.split(';')]\n",
        "tokenized_prompts = processor(prompts)\n",
        "tokenized_prompt = replicate(tokenized_prompts)\n",
        "\n",
        "# number of predictions per prompt\n",
        "n_predictions = number_of_images\n",
        "\n",
        "# We can customize generation parameters (see https://huggingface.co/blog/how-to-generate)\n",
        "gen_top_k = None\n",
        "gen_top_p = None\n",
        "temperature = None\n",
        "cond_scale = 10.0\n",
        "\n",
        "from flax.training.common_utils import shard_prng_key\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "op(c.title, 'Run id:', uniq_id)\n",
        "# print(f\"Prompts: {prompts}\\n\")\n",
        "# generate images\n",
        "images = []\n",
        "\n",
        "for i in trange(max(n_predictions // jax.device_count(), 1)):\n",
        "    # get a new key\n",
        "    key, subkey = jax.random.split(key)\n",
        "    # generate images\n",
        "    encoded_images = p_generate(\n",
        "        tokenized_prompt,\n",
        "        shard_prng_key(subkey),\n",
        "        params,\n",
        "        gen_top_k,\n",
        "        gen_top_p,\n",
        "        temperature,\n",
        "        cond_scale,\n",
        "    )\n",
        "    # remove BOS\n",
        "    encoded_images = encoded_images.sequences[..., 1:]\n",
        "    # decode images\n",
        "    decoded_images = p_decode(encoded_images, vqgan_params)\n",
        "    decoded_images = decoded_images.clip(0.0, 1.0).reshape((-1, 256, 256, 3))\n",
        "    for decoded_img in decoded_images:\n",
        "        img = Image.fromarray(np.asarray(decoded_img * 255, dtype=np.uint8))\n",
        "        images.append(img)\n",
        "        display(img)\n",
        "        if output_dir != '':\n",
        "          if superres is True:\n",
        "            # lr_img = np.array(img)\n",
        "            # lr_img = np.asarray(decoded_img * 255, dtype=np.uint8)\n",
        "            # lr_img = img\n",
        "            # lr_img = Image.fromarray(img)\n",
        "            # lr_img = np.asarray(img)\n",
        "            lr_img = np.array(img)\n",
        "            sr_img = rdn.predict(lr_img, by_patch_of_size=50)\n",
        "            img = Image.fromarray(sr_img)\n",
        "          timestamp = datetime.date.today().strftime('%Y%m%d')\n",
        "          img_filename = str(timestamp) + '_' + uniq_id + '_' + str(i) + '_' + (''.join(e for e in generate_image_of[:60].title() if e.isalnum()))+'.png'\n",
        "          img_path = dir_out+img_filename\n",
        "          # pil_image = TF.to_pil_image(images[k])\n",
        "          img.save(img_path)\n",
        "          # pil_image.save(f'{dir_output[k]}/{file_title}.png')\n",
        "        print()\n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print('\\nElapsed', timedelta(seconds=timer_end-timer_start))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}