{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CuYtwLUQ2zZWHjO8K4MXQMQcDRC116VT",
      "authorship_tag": "ABX9TyODwqRti2TZlQR847WD7Xx5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralTextToImage/blob/main/Fast_Dream_Booth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Fast Stable Diffusion <font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Neural text-to-image</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToImage\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "With this notebook you can train a custom Stable Diffusion model and run a Web UI to use it. This notebook is a modified version of [fast-stable-diffusion by TheLastBen](https://github.com/TheLastBen/fast-stable-diffusion), which in turn is based on [DreamBooth on Stable Diffusion by Xavier Xiao](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) and [stable-diffusion-webui by AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui).\n",
        "\n",
        "[Stable Diffusion](https://github.com/huggingface/diffusers) is a text-to-image latent diffusion model created by the researchers and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai) and [LAION](https://laion.ai).\n",
        "\n",
        "**Requirements** to run this notebook:\n",
        "- [Hugging Face](https://huggingface.co/) user account (register for free).\n",
        "- Agreeing to the terms of [v1-5 model card](https://huggingface.co/runwayml/stable-diffusion-v1-5).\n",
        "- Hugging Face access token, which can be found (or created) [here](https://huggingface.co/settings/tokens) when you have a user account.\n",
        "\n",
        "**Tips:**\n",
        "- All paths should be relative to your Google Drive root. E.g. if you have a directory called _images_ in your Google Drive, containing a subdirectory called _grayscale_, type `images/grayscale` as path.\n",
        "- `token` = your Hugging Face access token.\n",
        "- `work_path` is the \"root path\" where everything necessary is tored (your custom trained models, required repositories, output images, etc.) You may store your datasets somewhere under this directory as well.\n",
        "- Training is automatically continued if model is already found (by given name under `<work_path>/Sessions`). Otherwise a new model is trained.\n",
        "- `effective_word` is the word that you will use in your prompts to utilize your custom trained model.\n",
        "- You can use value `auto` in `steps` field, in which case 100 steps per image is automatically calculated.\n",
        "- `<work_path>/Sessions/<model_name>/meta/training_runs.txt` will contain information about done trainings.\n",
        "- _Train_ and _Run Web-UI_ cells are independent, run only as necessary. I.e. if you want to generate images and not train anything, skip the _Train_ cell and run _Run Web-UI_ cell only, etc."
      ],
      "metadata": {
        "id": "7Q7b0LCOxXuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = []\n",
        "pip_packages = ''\n",
        "apt_packages = ''\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "token = \"\" #@param {type:\"string\"}\n",
        "work_path = \"\" #@param{type: 'string'}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "\n",
        "store_models_to = work_path\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive is True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    os.symlink('/content/drive', '/content/gdrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if len(repositories) > 0 and skip_setup == False:\n",
        "  for repo in repositories:\n",
        "    %cd /content/\n",
        "    install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "    repo = repo if '.git' in repo else repo+'.git'\n",
        "    !git clone {repo}\n",
        "    if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "      !pip install -e ./{install_dir}\n",
        "    if os.path.isfile(install_dir+'requirements.txt'):\n",
        "      !pip install -r {install_dir}/requirements.txt\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %cd /usr/local/lib/python3.7/diffusers/\n",
        "  !rm /usr/local/lib/python3.7/diffusers/models/attention.py\n",
        "  wget.download('https://raw.githubusercontent.com/huggingface/diffusers/main/src/diffusers/models/attention.py')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/\n",
        "\n",
        "CKPT_Path = \"\" #@ param {type:\"string\"}\n",
        "CKPT_Link = \"\" #@ param {type:\"string\"}\n",
        "\n",
        "\n",
        "Compatiblity_Mode = False #@ param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "def downloadmodel():\n",
        "  global token\n",
        "  if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('\u001b[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        print('\u001b[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "        time.sleep(5)\n",
        "\n",
        "if CKPT_Path !=\"\":\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  if os.path.exists(str(CKPT_Path)):\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    with capture.capture_output() as cap:\n",
        "      if Compatiblity_Mode:\n",
        "        !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "      else:           \n",
        "        !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py      \n",
        "    !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$CKPT_Path\" --dump_path /content/stable-diffusion-v1-5\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mDONE !')\n",
        "    else:\n",
        "      !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "      !rm /content/v1-inference.yaml\n",
        "      !rm -r /content/stable-diffusion-v1-5\n",
        "      while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4.7GB CKPT instead of 7GB')\n",
        "        time.sleep(5)\n",
        "  else:\n",
        "    while not os.path.exists(str(CKPT_Path)):\n",
        "      print('\u001b[1;31mWrong path, use the colab file explorer to copy the path')\n",
        "      time.sleep(5)\n",
        "\n",
        "\n",
        "elif CKPT_Link !=\"\":   \n",
        "    if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      !rm -r /content/stable-diffusion-v1-5     \n",
        "    !gdown --fuzzy $CKPT_Link -O model.ckpt    \n",
        "    if os.path.exists('/content/model.ckpt'):\n",
        "      if os.path.getsize(\"/content/model.ckpt\") > 1810671599:\n",
        "        !mkdir /content/stable-diffusion-v1-5\n",
        "        with capture.capture_output() as cap: \n",
        "          if Compatiblity_Mode:\n",
        "            !wget https://raw.githubusercontent.com/huggingface/diffusers/039958eae55ff0700cfb42a7e72739575ab341f1/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "          else:           \n",
        "            !wget https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py                \n",
        "        !python /content/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.ckpt --dump_path /content/stable-diffusion-v1-5\n",
        "        if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "          clear_output()\n",
        "          print('\u001b[1;32mDONE !')\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm /content/v1-inference.yaml\n",
        "          !rm /content/model.ckpt\n",
        "        else:\n",
        "          if os.path.exists('/content/v1-inference.yaml'):\n",
        "            !rm /content/v1-inference.yaml\n",
        "          !rm /content/convert_original_stable_diffusion_to_diffusers.py\n",
        "          !rm -r /content/stable-diffusion-v1-5\n",
        "          !rm /content/model.ckpt\n",
        "          while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "            print('\u001b[1;31mConversion error, Insufficient RAM or corrupt CKPT, use a 4.7GB CKPT instead of 7GB')\n",
        "            time.sleep(5)\n",
        "      else:\n",
        "        while os.path.getsize('/content/model.ckpt') < 1810671599:\n",
        "          print('\u001b[1;31mWrong link, check that the link is valid')\n",
        "          time.sleep(5)\n",
        "else:\n",
        "  downloadmodel()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')\n",
        "print()\n",
        "\n",
        "dir_models = drive_root+fix_path(store_models_to)\n",
        "dir_sessions = dir_models+'Sessions/'\n",
        "dir_sys = dir_models+'sys/'\n",
        "\n",
        "op(c.title, 'Available trained models')\n",
        "print()\n",
        "session_dirs = glob(dir_sessions+'*')\n",
        "for dir in session_dirs:\n",
        "  word = get_from_txt(dir+'/meta/training_runs.txt', 'word', True)\n",
        "  print('ID:    ', basename(dir))\n",
        "  print('Phrase:', word)\n",
        "  print()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8GbW4eojmmqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Train <small><small><font color=#999>- Skip this cell if you only want to generate images (using one of your earlier custom models).</small></small>\n",
        "\n",
        "from glob import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "model_name = \"\" #@param{type: 'string'}\n",
        "effective_word = \"\" #@param{type: 'string'}\n",
        "source_images=\"\" #@param{type: 'string'}\n",
        "\n",
        "steps = \"auto\" #@param{type: 'string'}\n",
        "seed = -1 #@param{type: 'integer'}\n",
        "\n",
        "rename_word = effective_word\n",
        "\n",
        "if seed <= 0:\n",
        "  seed = int(time.time())\n",
        "\n",
        "store_to = drive_root+fix_path(store_models_to)\n",
        "\n",
        "resuming = False\n",
        "if os.path.isdir(store_to+'Sessions/'+model_name):\n",
        "  resuming = True\n",
        "\n",
        "if not os.path.isdir(store_to+'Sessions/'+model_name):\n",
        "  pics = list_images(drive_root+source_images)\n",
        "  total = len(pics)\n",
        "  exists = 0\n",
        "\n",
        "  if not os.path.isdir(drive_root+source_images+'/ren'):\n",
        "    os.mkdir(drive_root+source_images+'/ren')\n",
        "\n",
        "  for i, pic in enumerate(pics):\n",
        "    if i == 0:\n",
        "      new_name = os.path.dirname(pic) + '/ren/'+rename_word+path_ext(pic)\n",
        "    else:\n",
        "      new_name = os.path.dirname(pic) + '/ren/' + rename_word + ' (' + str(i) + ')'+path_ext(pic)\n",
        "    # new_name = pic.replace()\n",
        "    if not os.path.isfile(new_name):\n",
        "      shutil.copy(pic, new_name)\n",
        "    else:\n",
        "      exists = exists+1\n",
        "\n",
        "  if exists == 0:\n",
        "    print('DONE')\n",
        "  elif exists > 0 and exists < total:\n",
        "    print('DONE. Some of the images were already renamed.')\n",
        "  elif exists == total:\n",
        "    print('All images already renamed.')\n",
        "\n",
        "if os.path.isdir(drive_root+source_images+'/ren/'):\n",
        "  renamed_source_images = drive_root+source_images+'/ren/'\n",
        "else:\n",
        "  op(c.fail, 'Image dir does not exist')\n",
        "  sys.exit(0)\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "\n",
        "Use_New_Fast_Method= \"Yes\" #@ param [\"Yes\", \"No\"]\n",
        "\n",
        "if Use_New_Fast_Method==\"Yes\":\n",
        "\n",
        "  def fdownloadmodel():\n",
        "    token=input(\"Insert your huggingface token :\")\n",
        "    %cd /content/\n",
        "    !mkdir /content/stable-diffusion-v1-5\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo -e \"feature_extractor\\nsafety_checker\\nscheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "      !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "      !rm -r /content/stable-diffusion-v1-5/.git\n",
        "      %cd /content/    \n",
        "      clear_output()\n",
        "\n",
        "  MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
        "  PT=\"\"\n",
        "  With_Prior_Preservation = \"No\"\n",
        "  Captionned_instance_images = True\n",
        "  Save_class_images_to_gdrive = False\n",
        "  \n",
        "  \n",
        "  \n",
        "  Session_Name = model_name\n",
        "  # Session_Name = \"rusanen-all\" #@param{type: 'string'}\n",
        "  while Session_Name==\"\":\n",
        "    print('\u001b[1;31mInput the Session Name:') \n",
        "    Session_Name=input('')\n",
        "  INSTANCE_NAME=Session_Name\n",
        "\n",
        "  \n",
        "\n",
        "  WORKSPACE=store_to\n",
        "  OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
        "  SESSION_DIR=WORKSPACE+'Sessions/'+Session_Name\n",
        "  INSTANCE_DIR=WORKSPACE+\"Sessions/\"+Session_Name+\"/instance_images\"\n",
        "  MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
        "\n",
        "  dir_meta = SESSION_DIR+'/meta/'\n",
        "  \n",
        "\n",
        "  if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "    print('\u001b[1;32mLoading session with no previous model, downloading the original....')\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "        !rm -r '/content/stable-diffusion-v1-5'    \n",
        "      fdownloadmodel()\n",
        "    if not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "    else:\n",
        "      print('\u001b[1;32mSession Loaded, proceed to uploading instance images')\n",
        "\n",
        "  elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "    print('\u001b[1;32mSession found, loading the trained model ...')\n",
        "    %mkdir -p \"$OUTPUT_DIR\"\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\" --session_dir \"$SESSION_DIR\"\n",
        "    if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      resume=True    \n",
        "      !rm /content/v1-inference.yaml\n",
        "      clear_output()\n",
        "      print('\u001b[1;32mSession loaded.')\n",
        "    else:     \n",
        "      !rm /content/v1-inference.yaml\n",
        "      if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
        "\n",
        "\n",
        "  elif not os.path.exists(str(SESSION_DIR)):\n",
        "      if not os.path.isdir(SESSION_DIR):\n",
        "        os.mkdir(SESSION_DIR)\n",
        "      if not os.path.isdir(dir_meta):\n",
        "        os.mkdir(dir_meta)\n",
        "      %mkdir -p \"$INSTANCE_DIR\"\n",
        "      print('\u001b[1;32mCreating session...')\n",
        "      if not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "          !rm -r '/content/stable-diffusion-v1-5'\n",
        "        fdownloadmodel()\n",
        "      if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "        print('\u001b[1;32mSession created, proceed to uploading instance images')\n",
        "      else:\n",
        "        print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n",
        "      \n",
        "else:\n",
        "  print('\u001b[1;32mOk, proceed to the old method cell')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import shutil, os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "if Use_New_Fast_Method==\"Yes\":\n",
        "\n",
        "  Remove_existing_instance_images= True #@ param{type: 'boolean'}\n",
        "  \n",
        "\n",
        "\n",
        "  if Remove_existing_instance_images:\n",
        "    if os.path.exists(str(INSTANCE_DIR)):\n",
        "      !rm -r \"$INSTANCE_DIR\"\n",
        "\n",
        "  if not os.path.exists(str(INSTANCE_DIR)):\n",
        "    %mkdir -p \"$INSTANCE_DIR\"\n",
        "\n",
        "  IMAGES_FOLDER_OPTIONAL=renamed_source_images \n",
        "\n",
        "  # if os.path.isdir(IMAGES_FOLDER_OPTIONAL+'/ren'):\n",
        "  #   IMAGES_FOLDER_OPTIONAL = IMAGES_FOLDER_OPTIONAL+'/ren'\n",
        "\n",
        "  print( renamed_source_images )\n",
        "  print( IMAGES_FOLDER_OPTIONAL )\n",
        "\n",
        "  while IMAGES_FOLDER_OPTIONAL !=\"\" and not os.path.exists(str(IMAGES_FOLDER_OPTIONAL)):\n",
        "    print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "    IMAGES_FOLDER_OPTIONAL=input('')\n",
        "\n",
        "  if IMAGES_FOLDER_OPTIONAL!=\"\":\n",
        "    with capture.capture_output() as cap:\n",
        "      %cp -r \"$IMAGES_FOLDER_OPTIONAL/.\" \"$INSTANCE_DIR\"\n",
        "      %cd \"$INSTANCE_DIR\"\n",
        "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "      %cd /content\n",
        "      if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"     \n",
        "    print('\u001b[1;32mDone, proceed to the training cell')\n",
        "\n",
        "  elif IMAGES_FOLDER_OPTIONAL ==\"\":\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "      shutil.move(filename, INSTANCE_DIR)\n",
        "      clear_output()\n",
        "\n",
        "    with capture.capture_output() as cap:\n",
        "      %cd \"$INSTANCE_DIR\"\n",
        "      !find . -name \"* *\" -type f | rename 's/ /_/g'\n",
        "      %cd /content\n",
        "      if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "        %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"\n",
        "    print('\u001b[1;32mDone, proceed to the training cell')\n",
        "\n",
        "else:\n",
        "  print(('\u001b[1;31mSet the New_Fast_Method to Yes to use this cell'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_imgs = len(list_images(INSTANCE_DIR)) \n",
        "if steps == 'auto':\n",
        "  steps = int(total_imgs * 100)\n",
        "elif steps.isnumeric():\n",
        "  steps = int(steps)\n",
        "\n",
        "\n",
        "op(c.title, 'Prepare to train...')\n",
        "op(c.okb, 'Word: '+str(rename_word))\n",
        "op(c.okb, 'Images: '+str(total_imgs))\n",
        "op(c.okb, 'Steps: '+str(steps))\n",
        "op(c.okb, 'Seed: '+str(seed))\n",
        "\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "\n",
        "Resume_Training = resuming\n",
        "\n",
        "if not Resume_Training and not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r '/content/stable-diffusion-v1-5'\n",
        "  print('\u001b[1;31mOriginal model not found, downloading....\u001b[0m')\n",
        "  fdownloadmodel()\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "     print('\u001b[1;32mModel downloaded, proceeding to training...')\n",
        "  else:\n",
        "     print('\u001b[1;31mError downloading the model, make sure you have accepted the terms at https://huggingface.co/runwayml/stable-diffusion-v1-5')  \n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "Training_Steps=steps #500 #@ param{type: 'number'}\n",
        "Seed=seed ## 666666 #@ param{type: 'number'}\n",
        "\n",
        "fp16 = True\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "  %cd /usr/local/lib/python3.7/dist-packages/diffusers/models\n",
        "  !wget -O attention.py https://raw.githubusercontent.com/huggingface/diffusers/main/src/diffusers/models/attention.py\n",
        "  !pip uninstall -q xformers\n",
        "  %cd /content\n",
        "  clear_output()\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "  MODELT_NAME=MODEL_NAME\n",
        "\n",
        "\n",
        "Enable_text_encoder_training= True #@ param{type: 'boolean'}\n",
        "\n",
        "Train_text_encoder_for=40 #@ param{type: 'number'}\n",
        "\n",
        "if Train_text_encoder_for==100:\n",
        "  stptxt=Training_Steps+10\n",
        "elif Train_text_encoder_for==0:\n",
        "  Enable_text_encoder_training= False\n",
        "  stptxt=10\n",
        "else:\n",
        "  stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n",
        "\n",
        "if Enable_text_encoder_training:\n",
        "  Textenc=\"--train_text_encoder\"\n",
        "else:\n",
        "  Textenc=\"\"\n",
        "\n",
        "\n",
        "Save_Checkpoint_Every_n_Steps = False #@ param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@ param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@ param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "\n",
        "\n",
        "Caption=''\n",
        "if Captionned_instance_images:\n",
        "  Caption='--image_captions_filename'\n",
        "\n",
        "if With_Prior_Preservation=='No':\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    $Textenc \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --stop_text_encoder_training=$stptxt \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --center_crop \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "else:\n",
        "\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    $Textenc \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --class_data_dir=\"$CLASS_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --instance_prompt=\"$PT\"\\\n",
        "    --class_prompt=\"$CPT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --center_crop \\\n",
        "    --max_train_steps=$Training_Steps \\\n",
        "    --num_class_images=$SUBJECT_IMAGES\n",
        "\n",
        "\n",
        "if Save_class_images_to_gdrive:\n",
        "  if os.path.exists(str(CLASS_DIR)):\n",
        "    if not os.path.exists('/content/gdrive/MyDrive/Class_images'):\n",
        "      !mkdir /content/gdrive/MyDrive/Class_images\n",
        "    Class_gdir= '/content/gdrive/MyDrive/Class_images/'+SUBJECT_TYPE\n",
        "    if not os.path.exists(str(Class_gdir)):\n",
        "      !cp -r \"$CLASS_DIR\" /content/gdrive/MyDrive/Class_images\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  if Use_New_Fast_Method==\"No\":\n",
        "    !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
        "  else:\n",
        "    !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  if Use_New_Fast_Method==\"No\":  \n",
        "    if os.path.exists('/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'):\n",
        "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive\")\n",
        "    else:\n",
        "      print(\"\u001b[1;31mSomething went wrong\")\n",
        "  else:\n",
        "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "      if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "        !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "\n",
        "      stamp = timestamp(human_readable=True)\n",
        "      if resuming == False:\n",
        "        append_txt(dir_meta+'training_runs.txt', 'Training '+str(stamp)+'\\n'+'Images: '+str(total_imgs)+'\\n'+'Word: '+str(rename_word)+'\\n'+'Seed: '+str(seed)+'\\n'+'Steps: '+str(steps)+'\\n'+'\\n')\n",
        "      else:\n",
        "        append_txt(dir_meta+'training_runs.txt', 'Resumed training '+str(stamp)+'\\n'+'Images: '+str(total_imgs)+'\\n'+'Word: '+str(rename_word)+'\\n'+'Seed: '+str(seed)+'\\n'+'Steps: '+str(steps)+'\\n'+'\\n')\n",
        "      print(\"\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\")\n",
        "    else:\n",
        "      print(\"\u001b[1;31mSomething went wrong\")\n",
        "    \n",
        "else:\n",
        "  print(\"\u001b[1;31mSomething went wrong\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "t6hrVVOroPbr",
        "outputId": "a9b77814-1552-4a79-8260-64e432fcc127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Run web-UI <small><small><font color=#999>- Generate images</small></small>\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "Update_repo = False #@ param {type:\"boolean\"}\n",
        "use_model = \"\" #@param {type:\"string\"}\n",
        "\n",
        "INSTANCE__NAME=use_model\n",
        "\n",
        "\n",
        "\n",
        "if INSTANCE__NAME!=\"\":\n",
        "  INSTANCET=INSTANCE__NAME\n",
        "\n",
        "Use_Custom_Path = False #@ param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  INSTANCET=INSTANCE_NAME  \n",
        "  if Use_Custom_Path:\n",
        "    del INSTANCET\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "try:\n",
        "  Use_New_Fast_Method\n",
        "except:\n",
        "  Use_New_Fast_Method=\"\"\n",
        "\n",
        "try:\n",
        "  INSTANCET\n",
        "  if Use_New_Fast_Method==\"No\" or Use_New_Fast_Method==\"\":\n",
        "    path_to_trained_model=dir_sessions+INSTANCET+'/'+INSTANCET+'.ckpt'\n",
        "  else:\n",
        "    path_to_trained_model=dir_sessions+INSTANCET+'/'+INSTANCET+'.ckpt'\n",
        "except:\n",
        "  print('\u001b[1;31mIt seems that you did not perform training during this session \u001b[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
        "  path_to_trained_model=input()\n",
        "\n",
        "# print( path_to_trained_model )\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   print(\"\u001b[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "   path_to_trained_model=input()\n",
        "\n",
        "         \n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.isdir(dir_models+'sys'):\n",
        "    os.mkdir(dir_sys)\n",
        "  %cd {dir_sys}\n",
        "  !git clone https://github.com/CompVis/stable-diffusion\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "  %cd {dir_sys}stable-diffusion-webui/\n",
        "  !mkdir -p cache/{huggingface,torch}\n",
        "  %cd /content/\n",
        "  !ln -s {dir_sys}stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "  !ln -s {dir_sys}stable-diffusion-webui/cache/torch ../root/.cache/\n",
        "\n",
        "if Update_repo:\n",
        "  !rm {dir_sys}stable-diffusion-webui/webui.sh  \n",
        "  !rm {dir_sys}stable-diffusion-webui/modules/paths.py\n",
        "  !rm {dir_sys}stable-diffusion-webui/webui.py \n",
        "  !rm {dir_sys}stable-diffusion-webui/modules/ui.py\n",
        "  !rm {dir_sys}atable-diffusion-webui/style.css\n",
        "  %cd {dir_sys}stable-diffusion-webui/\n",
        "  clear_output()\n",
        "  print('\u001b[1;32m')\n",
        "  !git pull\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:  \n",
        "  if not os.path.exists(dir_sys+'stable-diffusion/src/k-diffusion/k_diffusion'):\n",
        "    os.mkdir(dir_sys+'stable-diffusion/src')\n",
        "    %cd {dir_sys}stable-diffusion/src\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/openai/CLIP\n",
        "    !mv {dir_sys}stable-diffusion/src/CLIP {dir_sys}stable-diffusion/src/clip\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "    !mv  {dir_sys}stable-diffusion/src/GFPGAN/gfpgan {dir_sys}stable-diffusion-webui\n",
        "    !git clone https://github.com/salesforce/BLIP\n",
        "    !mv  {dir_sys}stable-diffusion/src/BLIP {dir_sys}stable-diffusion/src/blip\n",
        "    !git clone https://github.com/sczhou/CodeFormer\n",
        "    !mv  {dir_sys}stable-diffusion/src/CodeFormer {dir_sys}stable-diffusion/src/codeformer\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN\n",
        "    !mv  {dir_sys}stable-diffusion/src/Real-ESRGAN/ {dir_sys}stable-diffusion/src/realesrgan\n",
        "    !git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "    !cp -r {dir_sys}stable-diffusion/src/k-diffusion/k_diffusion {dir_sys}stable-diffusion-webui\n",
        "    !git clone https://github.com/Hafiidz/latent-diffusion\n",
        "    !cp -r {dir_sys}stable-diffusion/ldm {dir_sys}stable-diffusion-webui/\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/usr/local/lib/python3.7/dist-packages/gradio-3.4b3.dist-info'):\n",
        "    %cd /content/\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.1\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.2\n",
        "    %mv Dependencies_AUT.1 Dependencies_AUT.7z.001\n",
        "    %mv Dependencies_AUT.2 Dependencies_AUT.7z.002\n",
        "    !7z x Dependencies_AUT.7z.001\n",
        "    time.sleep(2)\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers-4.19.2.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers-0.3.0.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/accelerate-0.12.0.dist-info    \n",
        "    !cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "    !rm -r /content/usr\n",
        "    !rm Dependencies_AUT.7z.001\n",
        "    !rm Dependencies_AUT.7z.002\n",
        "    %cd {dir_sys}stable-diffusion-webui/ldm/modules\n",
        "    if 'A100' in s:\n",
        "      !wget -O attention.py https://raw.githubusercontent.com/CompVis/stable-diffusion/main/ldm/modules/attention.py\n",
        "    else:\n",
        "      !wget -O attention.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "    \n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd {dir_sys}stable-diffusion-webui/modules\n",
        "  !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd {dir_sys}stable-diffusion-webui/\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
        "  !sed -i 's@gpu_call).*@gpu_call) \\n        demo.queue(concurrency_count=111500)@' {dir_sys}table-diffusion-webui/webui.py\n",
        "  %cd {dir_sys}stable-diffusion-webui/modules/\n",
        "  !wget -O ui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/modules/ui.py\n",
        "  !sed -i 's@css = \"\".*@with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:\\n        css = file.read()@' {dir_sys}stable-diffusion-webui/modules/ui.py  \n",
        "  %cd {dir_sys}stable-diffusion-webui\n",
        "  !wget -O style.css https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/style.css\n",
        "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' {dir_sys}stable-diffusion-webui/style.css  \n",
        "  %cd /content\n",
        "\n",
        "\n",
        "Use_Gradio_Server = False #@ param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  !sed -i '1037s@.*@            self.server_name = server_name@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = server_port@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\" if self.local_url.startswith(\"https\") else \"http\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  clear_output()\n",
        "  \n",
        "else:\n",
        "  share=''\n",
        "\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "  !sed -i '1037s@.*@            self.server_name = \"{srv[8:]}\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = 443@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "  clear_output()\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd {dir_sys}stable-diffusion/\n",
        "\n",
        "!python {dir_sys}stable-diffusion-webui/webui.py $share --disable-safe-unpickle --ckpt \"$path_to_trained_model\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "MWwLmOJXw1Fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}