{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fDv3mqRTd_GZRn_dEwfMRJlWVcaHQZLg",
      "authorship_tag": "ABX9TyMdx8IPX34tjJhT6fd9yZqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralTextToImage/blob/main/Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCskRiNym_LW"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Stable Diffusion <font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Neural text-to-image</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToImage\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Generate images from text prompt using [Stable Diffusion](https://github.com/huggingface/diffusers). Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai) and [LAION](https://laion.ai).\n",
        "\n",
        "**Requirements** to run this notebook:\n",
        "- [Hugging Face](https://huggingface.co/) user account (register for free).\n",
        "- Agreeing to the terms of used model card: [v1.4](https://huggingface.co/CompVis/stable-diffusion-v1-4), [v1.5](https://huggingface.co/runwayml/stable-diffusion-v1-5).\n",
        "- Hugging Face access token, which can be found (or created) [here](https://huggingface.co/settings/tokens) when you have a user account.\n",
        "\n",
        "**Tips:**\n",
        "- You may queue multiple prompts in one run by separating them with `;`.\n",
        "- Enter `output_dir` relative to your Google Drive root. E.g. `ai/images` if you have a directory in your Drive called _ai_, containing a subdirectory called _images_.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6-8KXU6m8TM",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "pip_packages = 'diffusers==0.2.4 transformers scipy ftfy'\n",
        "main_repository = ''\n",
        "\n",
        "#@markdown Copy-paste your Hugging Face access token in the field below prior to executing this cell. You can find your access token [here](https://huggingface.co/settings/tokens).\n",
        "access_token = \"\" #@param {type:\"string\"}\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\" #@param [\"CompVis/stable-diffusion-v1-4\", \"runwayml/stable-diffusion-v1-5\", \"hakurei/waifu-diffusion\"]\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive is True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if main_repository is not '':\n",
        "  !git clone {main_repository}\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "  assert len(imgs) == rows*cols\n",
        "  w, h = imgs[0].size\n",
        "  grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "  grid_w, grid_h = grid.size\n",
        "  \n",
        "  for i, img in enumerate(imgs):\n",
        "    grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "  return grid\n",
        "\n",
        "def whatGPU():\n",
        "  x = !nvidia-smi\n",
        "  g = ''.join(x);\n",
        "  gpu = 'None'\n",
        "  if 'A100' in g:\n",
        "    gpu = 'A100'\n",
        "    restart = True\n",
        "  elif 'V100' in g:\n",
        "    gpu = 'V100'\n",
        "  elif 'P100' in g:\n",
        "    gpu = 'P100'\n",
        "  elif 'T4' in g:\n",
        "    gpu = 'T4'\n",
        "  else:\n",
        "    gpu = '?'\n",
        "  return gpu  \n",
        "\n",
        "def aspectRatioToPixels(aspect_ratio='1:1', max_px=704*704):\n",
        "  w, h = [int(x) for x in aspect_ratio.split(':')]\n",
        "  nw = math.floor(math.sqrt(max_px/h*w));\n",
        "  nh = math.floor(math.sqrt(max_px/w*h));\n",
        "  nw = (nw+0x20)&(~0x3f);\n",
        "  nh = (nh+0x20)&(~0x3f);\n",
        "  return nw, nh\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=access_token)\n",
        "\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Uncomment this to disable NSFW filter\n",
        "# pipe.safety_checker = lambda images, **kwargs: (images, False)\n",
        "\n",
        "from torch import autocast\n",
        "gpu = whatGPU()\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2z1os4Bocdy",
        "cellView": "form"
      },
      "source": [
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #S̛̞̩͎͓ ̦̤͉͚̏ ̧̠͋͘ͅl͕̞͕̝͗̐͘.̠̰̳̫̈́̚ ̡͉̼̩̬̈́̇͒͘ȩ̨͎͛̔͆͊̏͜ͅ.͕̩̹̠̕͜ ̛̦̦̮e̢͐͊͂̀̊ͅ ̜̙̝̊͋ ̬̝̱̱͗p̮̎̽̌\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "generate_image_of = \"\" #@param {type:\"string\"}\n",
        "aspect_ratio = \"1:1 - square\" #@param [\"1:1 - square\", \"4:3 - landscape\", \"16:9 - wide\", \"3:4 - portrait\", \"9:16 - tall\"]\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "batch_size = 3 #@param {type:\"integer\"}\n",
        "repeats = 1 #@param {type:\"integer\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Defaults\n",
        "width = None \n",
        "height = None \n",
        "steps = 100\n",
        "guidance_scale = 7.5\n",
        "\n",
        "# Uncommentable advanced settings. Uncomment for fields.\n",
        "# Width and height are automatically used instead of aspect_ratio, if uncommented.\n",
        "#\n",
        "# width = 704 #@param {type:\"slider\", min:256, max:1152}\n",
        "# height = 704 #@param {type:\"slider\", min:256, max:1152}\n",
        "#\n",
        "# steps = 100 #@param {type:\"integer\"}\n",
        "# guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "\n",
        "# Max total pixels on P100 is 704x704, but will produce slightly less coherent images.\n",
        "# You may increase this for whatever your GPU can handle. Use multiples of 64.\n",
        "max_resolution = 512*512\n",
        "\n",
        "uniq_id = gen_id()\n",
        "\n",
        "if output_dir == '':\n",
        "  dir_out = dir_tmp\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "\n",
        "if width is not None and height is not None:\n",
        "  w = width\n",
        "  h = height\n",
        "else:\n",
        "  w, h = aspectRatioToPixels(aspect_ratio.split(' ')[0], max_resolution)\n",
        "\n",
        "if generate_image_of is 'pre':\n",
        "  prompts = predefined_prompts\n",
        "else:\n",
        "  if ';' in generate_image_of:\n",
        "    prompts = [x.strip() for x in generate_image_of.split(';')]\n",
        "  else:\n",
        "    prompts = [generate_image_of]\n",
        "\n",
        "if repeats > 1:\n",
        "  prompts = prompts * repeats\n",
        "\n",
        "if seed is '': seed = 0\n",
        "\n",
        "if batch_size < 1: batch_size = 1\n",
        "total = len(prompts)\n",
        "\n",
        "op(c.okb, 'Run id: '+uniq_id)\n",
        "for ii, prompt in enumerate(prompts):\n",
        "  img_row = []\n",
        "  n = ii+1\n",
        "  print()\n",
        "  op(c.title, 'Generating '+str(n)+'/'+str(total)+' ('+str(batch_size)+'x):', prompt, time=True)\n",
        "  for i in range(batch_size):\n",
        "    stamp = int(time.time())\n",
        "    new_seed = seed if seed != 0 else stamp\n",
        "    nn = i+1\n",
        "    op(c.okb, 'Image '+str(nn)+'/'+str(batch_size)+', seed: '+str(new_seed), time=True)\n",
        "    with autocast(\"cuda\"):\n",
        "      images = pipe(prompt, height=h, width=w, guidance_scale=guidance_scale, num_inference_steps=steps, generator=torch.Generator(\"cuda\").manual_seed(new_seed))[\"sample\"]\n",
        "    img_row.extend(images)\n",
        "    for iii, image in enumerate(images):\n",
        "      nnn = iii+1\n",
        "      file_out = uniq_id+'_'+str(n)+'-'+str(nn)+'_'+slug(prompt)[:50]+'_'+str(new_seed)+'.png'\n",
        "      image.save(dir_out+file_out)\n",
        "  grid = image_grid(img_row, rows=1, cols=batch_size)\n",
        "  display(grid)\n",
        "\n",
        "op(c.ok, 'Images saved in', dir_out.replace(drive_root, ''), time=True)\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "elapsed = timedelta(seconds=timer_end-timer_start)\n",
        "op(c.okb, 'Elapsed '+str(elapsed))\n",
        "op(c.ok, 'FIN.', time=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}