{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stable Diffusion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fDv3mqRTd_GZRn_dEwfMRJlWVcaHQZLg",
      "authorship_tag": "ABX9TyNTjZ8s32/geNp8GkiErvzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralTextToImage/blob/main/Stable_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCskRiNym_LW"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Stable Diffusion <font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Neural text-to-image</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToImage\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Generate images from text prompt using [Stable Diffusion](https://github.com/huggingface/diffusers). Stable Diffusion is a text-to-image latent diffusion model created by the researchers and engineers from [CompVis](https://github.com/CompVis), [Stability AI](https://stability.ai) and [LAION](https://laion.ai).\n",
        "\n",
        "**Requirements** to run this notebook:\n",
        "- [Hugging Face](https://huggingface.co/) user account (register for free).\n",
        "- Agreeing to the terms of [v1-4 model card](https://huggingface.co/CompVis/stable-diffusion-v1-4).\n",
        "- Hugging Face access token, which can be found [here](https://huggingface.co/settings/tokens) when you have a user account.\n",
        "\n",
        "**Tips:**\n",
        "- You may queue multiple prompts in one run by separating them with `;`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6-8KXU6m8TM",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "\n",
        "force_setup = False\n",
        "pip_packages = 'diffusers==0.2.4 transformers scipy ftfy'\n",
        "main_repository = ''\n",
        "\n",
        "#@markdown Copy-paste your [Hugging Face access token from this page](https://huggingface.co/settings/tokens) in the field below prior to executing this cell.\n",
        "access_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive is True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if main_repository is not '':\n",
        "  !git clone {main_repository}\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "!pip install \"ipywidgets>=7,<8\"\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "  assert len(imgs) == rows*cols\n",
        "\n",
        "  w, h = imgs[0].size\n",
        "  grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "  grid_w, grid_h = grid.size\n",
        "  \n",
        "  for i, img in enumerate(imgs):\n",
        "    grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "  return grid\n",
        "  \n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=access_token)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Disable NSFW filter\n",
        "# pipe.safety_checker = lambda images, **kwargs: (images, False)\n",
        "\n",
        "from torch import autocast\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'Setup finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2z1os4Bocdy",
        "cellView": "form"
      },
      "source": [
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown #S̛̞̩͎͓ ̦̤͉͚̏ ̧̠͋͘ͅl͕̞͕̝͗̐͘.̠̰̳̫̈́̚ ̡͉̼̩̬̈́̇͒͘ȩ̨͎͛̔͆͊̏͜ͅ.͕̩̹̠̕͜ ̛̦̦̮e̢͐͊͂̀̊ͅ ̜̙̝̊͋ ̬̝̱̱͗p̮̎̽̌\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "generate_image_of = \"\" #@param {type:\"string\"}\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "batch_size = 1 #@param {type:\"integer\"}\n",
        "repeats = 1 #@param {type:\"integer\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "uniq_id = gen_id()\n",
        "\n",
        "# Input\n",
        "# input_is_dir = False\n",
        "# if os.path.isdir(drive_root+input) or '*' in input:\n",
        "#   input_is_dir = True\n",
        "#   if not '*' in input:\n",
        "#     input = drive_root+fix_path(input)\n",
        "#     dir_in = input\n",
        "#     inputs = glob(dir_in+'/*')\n",
        "#   else:\n",
        "#     inputs = glob(drive_root+input)\n",
        "\n",
        "# elif os.path.isfile(drive_root+input):\n",
        "#   input = drive_root+input\n",
        "#   dir_in = path_dir(input)\n",
        "# else:\n",
        "#   op(c.fail, 'Input not found')\n",
        "#   sys.exit('Input not found')\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_tmp\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "  \n",
        "timer_start = time.time()\n",
        "\n",
        "if generate_image_of is 'pre':\n",
        "  prompts = predefined_prompts\n",
        "else:\n",
        "  if ';' in generate_image_of:\n",
        "    prompts = [x.strip() for x in generate_image_of.split(';')]\n",
        "  else:\n",
        "    prompts = [generate_image_of]\n",
        "\n",
        "if repeats > 1:\n",
        "  prompts = prompts * repeats\n",
        "\n",
        "if batch_size < 1: batch_size = 1\n",
        "total = len(prompts) * batch_size\n",
        "\n",
        "for ii, prompt in enumerate(prompts):\n",
        "  img_row = []\n",
        "  n = ii+1\n",
        "  op(c.title, 'Generating '+str(n)+'/'+str(total)+' ('+str(batch_size)+'x):', prompt, time=True)\n",
        "  op(c.okb, 'Seed:', str(seed), time=True)\n",
        "  for i in range(batch_size):\n",
        "    new_seed = seed if seed != 0 else int(time.time()) \n",
        "    with autocast(\"cuda\"):\n",
        "      images = pipe(prompt, generator=torch.Generator(\"cuda\").manual_seed(new_seed))[\"sample\"]\n",
        "    img_row.extend(images)\n",
        "    for image in images:\n",
        "      file_out = uniq_id+'_'+slug(prompt)[:50]+'_'+str(i).zfill(3)+'.png'\n",
        "      image.save(dir_out+file_out)\n",
        "  grid = image_grid(img_row, rows=1, cols=batch_size)\n",
        "  display(grid)\n",
        "\n",
        "op(c.ok, 'Images saved in', dir_out.replace(drive_root, ''), time=True)\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print('\\nElapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.', time=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}